{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3aaab-80f5-44b6-b663-b73bd2d815d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure du train_data :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30600 entries, 0 to 30613\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  30600 non-null  object\n",
      " 1   Label     30600 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 717.2+ KB\n",
      "None\n",
      "\n",
      "Statistiques :\n",
      "                                 Sentence         Label\n",
      "count                               30600  30600.000000\n",
      "unique                              30600           NaN\n",
      "top     \" or pg_sleep  (  __TIME__  )  --           NaN\n",
      "freq                                    1           NaN\n",
      "mean                                  NaN      0.370654\n",
      "std                                   NaN      0.482988\n",
      "min                                   NaN      0.000000\n",
      "25%                                   NaN      0.000000\n",
      "50%                                   NaN      0.000000\n",
      "75%                                   NaN      1.000000\n",
      "max                                   NaN      1.000000\n",
      "\n",
      "Structure du test_data :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 33726 entries, 0 to 33759\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  33725 non-null  object\n",
      " 1   Label     33726 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 790.5+ KB\n",
      "None\n",
      "Epoch 1/30\n",
      "383/383 [==============================] - 103s 253ms/step - loss: 0.1442 - accuracy: 0.9377 - val_loss: 0.0231 - val_accuracy: 0.9962\n",
      "Epoch 2/30\n",
      "383/383 [==============================] - 97s 255ms/step - loss: 0.0303 - accuracy: 0.9949 - val_loss: 0.0230 - val_accuracy: 0.9964\n",
      "Epoch 3/30\n",
      "383/383 [==============================] - 98s 255ms/step - loss: 0.0375 - accuracy: 0.9935 - val_loss: 0.0230 - val_accuracy: 0.9964\n",
      "Epoch 4/30\n",
      "383/383 [==============================] - 98s 255ms/step - loss: 0.0259 - accuracy: 0.9958 - val_loss: 0.0215 - val_accuracy: 0.9966\n",
      "Epoch 5/30\n",
      "383/383 [==============================] - 97s 254ms/step - loss: 0.0255 - accuracy: 0.9959 - val_loss: 0.0214 - val_accuracy: 0.9966\n",
      "Epoch 6/30\n",
      "383/383 [==============================] - 97s 254ms/step - loss: 0.0255 - accuracy: 0.9959 - val_loss: 0.0215 - val_accuracy: 0.9966\n",
      "Epoch 7/30\n",
      "383/383 [==============================] - 98s 255ms/step - loss: 0.0250 - accuracy: 0.9960 - val_loss: 0.0216 - val_accuracy: 0.9966\n",
      "Epoch 8/30\n",
      "383/383 [==============================] - 97s 252ms/step - loss: 0.0251 - accuracy: 0.9960 - val_loss: 0.0216 - val_accuracy: 0.9966\n",
      "Epoch 9/30\n",
      "383/383 [==============================] - 99s 258ms/step - loss: 0.0242 - accuracy: 0.9961 - val_loss: 0.0214 - val_accuracy: 0.9966\n",
      "Epoch 10/30\n",
      "383/383 [==============================] - 92s 240ms/step - loss: 0.0242 - accuracy: 0.9961 - val_loss: 0.0214 - val_accuracy: 0.9966\n",
      "Epoch 11/30\n",
      "383/383 [==============================] - 92s 240ms/step - loss: 0.0243 - accuracy: 0.9961 - val_loss: 0.0214 - val_accuracy: 0.9966\n",
      "Epoch 12/30\n",
      "383/383 [==============================] - 93s 242ms/step - loss: 0.0237 - accuracy: 0.9962 - val_loss: 0.0215 - val_accuracy: 0.9966\n",
      "Epoch 13/30\n",
      "383/383 [==============================] - 94s 245ms/step - loss: 0.0237 - accuracy: 0.9962 - val_loss: 0.0214 - val_accuracy: 0.9966\n",
      "Epoch 14/30\n",
      "383/383 [==============================] - 93s 242ms/step - loss: 0.0235 - accuracy: 0.9962 - val_loss: 0.0215 - val_accuracy: 0.9966\n",
      "Epoch 15/30\n",
      "383/383 [==============================] - 93s 242ms/step - loss: 0.1326 - accuracy: 0.9357 - val_loss: 0.3824 - val_accuracy: 0.7886\n",
      "Epoch 16/30\n",
      "383/383 [==============================] - 92s 240ms/step - loss: 0.3349 - accuracy: 0.8170 - val_loss: 0.0671 - val_accuracy: 0.9855\n",
      "Epoch 17/30\n",
      "383/383 [==============================] - 93s 242ms/step - loss: 0.0458 - accuracy: 0.9885 - val_loss: 0.0252 - val_accuracy: 0.9961\n",
      "Epoch 18/30\n",
      "383/383 [==============================] - 93s 242ms/step - loss: 0.0141 - accuracy: 0.9981 - val_loss: 0.0240 - val_accuracy: 0.9962\n",
      "Epoch 19/30\n",
      "383/383 [==============================] - 93s 243ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.0295 - val_accuracy: 0.9956\n",
      "Epoch 20/30\n",
      "383/383 [==============================] - 93s 242ms/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 0.0330 - val_accuracy: 0.9953\n",
      "Epoch 21/30\n",
      "383/383 [==============================] - 93s 242ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.0437 - val_accuracy: 0.9930\n",
      "Epoch 22/30\n",
      "383/383 [==============================] - 93s 243ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.0170 - val_accuracy: 0.9974\n",
      "Epoch 23/30\n",
      "383/383 [==============================] - 93s 243ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.0170 - val_accuracy: 0.9974\n",
      "Epoch 24/30\n",
      "383/383 [==============================] - 93s 243ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.0185 - val_accuracy: 0.9969\n",
      "Epoch 25/30\n",
      "383/383 [==============================] - 91s 238ms/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 0.0193 - val_accuracy: 0.9964\n",
      "Epoch 26/30\n",
      "383/383 [==============================] - 91s 237ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.0187 - val_accuracy: 0.9964\n",
      "Epoch 27/30\n",
      "383/383 [==============================] - 91s 238ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.0240 - val_accuracy: 0.9959\n",
      "Epoch 28/30\n",
      "383/383 [==============================] - 93s 243ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0396 - val_accuracy: 0.9935\n",
      "Epoch 29/30\n",
      "383/383 [==============================] - 105s 274ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.0594 - val_accuracy: 0.9910\n",
      "Epoch 30/30\n",
      "383/383 [==============================] - 101s 265ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9912\n",
      "1054/1054 [==============================] - 44s 42ms/step - loss: 0.0659 - accuracy: 0.9906\n",
      "\n",
      "✅ Test Accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 1. Chargement des données\n",
    "train_data = pd.read_csv('SQLIV3_cleaned2.csv')\n",
    "test_data = pd.read_csv('sqliv2_utf8.csv')\n",
    "\n",
    "# 2. Suppression des doublons (en gardant la première occurrence)\n",
    "train_data.drop_duplicates(subset='Sentence', keep='first', inplace=True)\n",
    "test_data.drop_duplicates(subset='Sentence', keep='first', inplace=True)\n",
    "\n",
    "# 3. Affichage de la structure des datasets\n",
    "print(\"Structure du train_data :\")\n",
    "print(train_data.info())\n",
    "print(\"\\nStatistiques :\")\n",
    "print(train_data.describe(include='all'))\n",
    "\n",
    "print(\"\\nStructure du test_data :\")\n",
    "print(test_data.info())\n",
    "\n",
    "# 4. Nettoyage minimal (on garde les caractères spéciaux)\n",
    "def clean_text(text):\n",
    "    return str(text).strip()\n",
    "\n",
    "train_data['Sentence'] = train_data['Sentence'].apply(clean_text)\n",
    "test_data['Sentence'] = test_data['Sentence'].apply(clean_text)\n",
    "\n",
    "# 5. Tokenisation\n",
    "vocab_size = 15000\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=vocab_size,\n",
    "    oov_token=\"<OOV>\",\n",
    "    filters='',        # Garde les caractères spéciaux\n",
    "    lower=False\n",
    ")\n",
    "tokenizer.fit_on_texts(train_data['Sentence'])\n",
    "\n",
    "# 6. Séquences et padding\n",
    "max_len = int(np.percentile([len(x.split()) for x in train_data['Sentence']], 95))\n",
    "X = tokenizer.texts_to_sequences(train_data['Sentence'])\n",
    "X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "y = train_data['Label'].astype('int')\n",
    "\n",
    "# 7. Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 8. Architecture du modèle LSTM\n",
    "embedding_dim = 256\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    LSTM(256, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(128),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 9. Compilation du modèle\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 11. Entraînement\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "# 12. Préparation des données de test\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Sentence'])\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=max_len)\n",
    "y_test = test_data['Label'].astype('int')\n",
    "\n",
    "# 13. Évaluation\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'\\n✅ Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50eebc77-3b73-4c60-a226-e48aa7dd02ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Nombre total de requêtes spam dans test_data : 11424\n",
      "357/357 [==============================] - 17s 43ms/step\n",
      "✅ Spams correctement détectés : 11362\n",
      "📊 Taux de détection : 99.46%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Récupérer uniquement les lignes spam (Label = 1)\n",
    "spam_only = test_data[test_data['Label'] == 1].copy()\n",
    "print(f\"\\n📌 Nombre total de requêtes spam dans test_data : {len(spam_only)}\")\n",
    "\n",
    "# 2. Nettoyage si besoin\n",
    "spam_only['Sentence'] = spam_only['Sentence'].apply(clean_text)\n",
    "\n",
    "# 3. Tokenisation + Padding\n",
    "X_spam = tokenizer.texts_to_sequences(spam_only['Sentence'])\n",
    "X_spam = pad_sequences(X_spam, padding='post', maxlen=max_len)\n",
    "\n",
    "# 4. Prédiction\n",
    "spam_preds = model.predict(X_spam)\n",
    "spam_preds_labels = (spam_preds > 0.5).astype(int)\n",
    "\n",
    "# 5. Calcul du nombre de spams correctement détectés\n",
    "true_positives = np.sum(spam_preds_labels == 1)\n",
    "total_spams = len(spam_only)\n",
    "detection_rate = (true_positives / total_spams) * 100\n",
    "\n",
    "# 6. Affichage\n",
    "print(f\"✅ Spams correctement détectés : {true_positives}\")\n",
    "print(f\"📊 Taux de détection : {detection_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9ed50-1e09-40a8-9dd8-c0a449d79785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
