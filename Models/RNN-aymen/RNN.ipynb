{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2c05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Dropout, Embedding\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139ecf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chargement des données\n",
    "train_data = pd.read_csv('SQLIV3_cleaned2.csv')\n",
    "test_data = pd.read_csv('sqliv2_utf8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e0253f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Suppression des doublons (en gardant la première occurrence)\n",
    "train_data.drop_duplicates(subset='Sentence', keep='first', inplace=True)\n",
    "test_data.drop_duplicates(subset='Sentence', keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7695a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Nettoyage MINIMAL (on conserve les caractères spéciaux !)\n",
    "def clean_text(text):\n",
    "    text = str(text).strip()  # Conversion en string + suppression espaces inutiles\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27379a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Sentence'] = train_data['Sentence'].apply(clean_text)\n",
    "test_data['Sentence'] = test_data['Sentence'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf8f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tokenisation (on garde tous les caractères)\n",
    "vocab_size = 15000  # Vocabulaire large pour les motifs SQL\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=vocab_size,\n",
    "    oov_token=\"<OOV>\",\n",
    "    filters='',       # ← AUCUN filtre (conserve ', \", ;, -- etc.)\n",
    "    lower=False       # ← Conserve la casse (important pour SQL)\n",
    ")\n",
    "tokenizer.fit_on_texts(train_data['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd342989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Padding adaptatif\n",
    "max_len = int(np.percentile([len(x.split()) for x in train_data['Sentence']], 95))\n",
    "X = tokenizer.texts_to_sequences(train_data['Sentence'])\n",
    "X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "y = train_data['Label'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba86f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Split train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad4c9731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS ROG\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7. Architecture du modèle\n",
    "embedding_dim = 256  # Grande dimension pour les caractères spéciaux\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    SimpleRNN(256, return_sequences=True),  # Couche 1: capture les motifs locaux\n",
    "    Dropout(0.3),\n",
    "    SimpleRNN(128),                         # Couche 2: agrège les motifs\n",
    "    Dense(64, activation='relu'),           # Couche dense intermédiaire\n",
    "    Dense(1, activation='sigmoid')          # Sortie binaire\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f863064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Optimisation\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec20ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 261ms/step - accuracy: 0.9450 - loss: 0.1495 - val_accuracy: 0.9966 - val_loss: 0.0195\n",
      "Epoch 2/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 241ms/step - accuracy: 0.9957 - loss: 0.0185 - val_accuracy: 0.9972 - val_loss: 0.0121\n",
      "Epoch 3/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 158ms/step - accuracy: 0.9975 - loss: 0.0113 - val_accuracy: 0.9975 - val_loss: 0.0113\n",
      "Epoch 4/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 153ms/step - accuracy: 0.9989 - loss: 0.0072 - val_accuracy: 0.9956 - val_loss: 0.0163\n",
      "Epoch 5/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 174ms/step - accuracy: 0.9992 - loss: 0.0061 - val_accuracy: 0.9953 - val_loss: 0.0176\n",
      "Epoch 6/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 179ms/step - accuracy: 0.9992 - loss: 0.0061 - val_accuracy: 0.9949 - val_loss: 0.0216\n",
      "Epoch 7/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 166ms/step - accuracy: 0.9988 - loss: 0.0077 - val_accuracy: 0.9959 - val_loss: 0.0144\n",
      "Epoch 8/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 173ms/step - accuracy: 0.9986 - loss: 0.0090 - val_accuracy: 0.9951 - val_loss: 0.0228\n",
      "Epoch 9/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 157ms/step - accuracy: 0.9989 - loss: 0.0068 - val_accuracy: 0.9951 - val_loss: 0.0215\n",
      "Epoch 10/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 169ms/step - accuracy: 0.9983 - loss: 0.0096 - val_accuracy: 0.9956 - val_loss: 0.0206\n",
      "Epoch 11/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 153ms/step - accuracy: 0.9992 - loss: 0.0057 - val_accuracy: 0.9944 - val_loss: 0.0300\n",
      "Epoch 12/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 164ms/step - accuracy: 0.9990 - loss: 0.0062 - val_accuracy: 0.9941 - val_loss: 0.0285\n",
      "Epoch 13/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 154ms/step - accuracy: 0.9989 - loss: 0.0070 - val_accuracy: 0.9941 - val_loss: 0.0320\n",
      "Epoch 14/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 179ms/step - accuracy: 0.9985 - loss: 0.0088 - val_accuracy: 0.9917 - val_loss: 0.0529\n",
      "Epoch 15/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 164ms/step - accuracy: 0.9991 - loss: 0.0058 - val_accuracy: 0.7967 - val_loss: 0.6233\n",
      "Epoch 16/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 215ms/step - accuracy: 0.9919 - loss: 0.0321 - val_accuracy: 0.9971 - val_loss: 0.0209\n",
      "Epoch 17/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 158ms/step - accuracy: 0.9990 - loss: 0.0069 - val_accuracy: 0.9943 - val_loss: 0.0280\n",
      "Epoch 18/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 178ms/step - accuracy: 0.9990 - loss: 0.0069 - val_accuracy: 0.9943 - val_loss: 0.0316\n",
      "Epoch 19/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 220ms/step - accuracy: 0.9990 - loss: 0.0066 - val_accuracy: 0.9954 - val_loss: 0.0239\n",
      "Epoch 20/20\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 203ms/step - accuracy: 0.9990 - loss: 0.0058 - val_accuracy: 0.9936 - val_loss: 0.0410\n"
     ]
    }
   ],
   "source": [
    "# 9. Entraînement\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97be91fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 37ms/step - accuracy: 0.9875 - loss: 0.0756\n",
      "\n",
      "Test Accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# 10. Évaluation\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Sentence'])\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=max_len)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, test_data['Label'].astype('int'))\n",
    "print(f'\\nTest Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca1993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Nombre total des injection sql dans test_data : 11424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Récupérer uniquement les lignes spam (Label = 1)\n",
    "sqli_only = test_data[test_data['Label'] == 1].copy()\n",
    "print(f\"\\n📌 Nombre total des injection sql dans test_data : {len(sqli_only)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edc7c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Nettoyage si besoin\n",
    "sqli_only['Sentence'] = sqli_only['Sentence'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2085149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenisation + Padding\n",
    "X_sqli = tokenizer.texts_to_sequences(sqli_only['Sentence'])\n",
    "X_sqli = pad_sequences(X_sqli, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5460318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# 4. Prédiction\n",
    "sqli_preds = model.predict(X_sqli)\n",
    "sqli_preds_labels = (sqli_preds > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "856889c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calcul du nombre de spams correctement détectés\n",
    "true_positives = np.sum(sqli_preds_labels == 1)\n",
    "total_sqli = len(sqli_only)\n",
    "detection_rate = (true_positives / total_sqli) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dfc0a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spams correctement détectés : 11359\n",
      "📊 Taux de détection : 99.43%\n"
     ]
    }
   ],
   "source": [
    "# 6. Affichage\n",
    "print(f\"✅ Spams correctement détectés : {true_positives}\")\n",
    "print(f\"📊 Taux de détection : {detection_rate:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
